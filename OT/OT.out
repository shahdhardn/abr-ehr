dataset=mimic
cost=combined
meta_set=whole
batch_size=16
num_classes=2
imb_factor=0.005
epochs=14
lr=2e-05
momentum=0.9
nesterov=True
weight_decay=0.0005
no_cuda=False
print_freq=100
gpu=0
save_name=OT_ARF12_imb0.005
idx=ours
model=Bert
seed=42
train data size:  6626
validation data size:  1389
test data size:  1378
train batches=  415  batches
validation batches=  87  batches
test batches=  87  batches
Epoch: [0][0/415]	Loss 19.0068 (19.0068)	F1 0.448 (0.448)	AUROC 0.500 (0.500)	AUPR 0.594 (0.594)	Prec@1 81.250 (81.250)
Epoch: [0][100/415]	Loss 4.8923 (11.1279)	F1 1.000 (0.504)	AUROC 0.500 (0.510)	AUPR 0.500 (0.314)	Prec@1 100.000 (79.394)
Epoch: [0][200/415]	Loss 7.7361 (11.2948)	F1 0.714 (0.494)	AUROC 0.933 (0.505)	AUPR 0.667 (0.313)	Prec@1 87.500 (79.104)
Epoch: [0][300/415]	Loss 9.4397 (11.1903)	F1 0.714 (0.488)	AUROC 0.714 (0.499)	AUPR 0.531 (0.302)	Prec@1 87.500 (78.862)
Epoch: [0][400/415]	Loss 9.5117 (11.0755)	F1 0.448 (0.488)	AUROC 0.433 (0.495)	AUPR 0.031 (0.301)	Prec@1 81.250 (79.068)
Epoch: [0][414/415]	Loss 5.8246 (11.0967)	F1 1.000 (0.489)	AUROC 0.500 (0.496)	AUPR 0.500 (0.305)	Prec@1 100.000 (79.264)
Test: [86/87]	Time 0.024 (0.145)	Loss 0.2500 (0.3809)	F1 1.000 (0.553)	AUROC 0.500 (0.500)	AUPR 0.500 (0.553)	Prec@1 100.000 (89.478)
 * Prec@1 89.478
 * F1 0.553
 * AUROC 0.500
 * AUPR 0.553
Epoch: [1][0/415]	Loss 10.4184 (10.4184)	F1 0.467 (0.467)	AUROC 0.467 (0.467)	AUPR 0.031 (0.031)	Prec@1 87.500 (87.500)
Epoch: [1][100/415]	Loss 4.8969 (9.9060)	F1 0.484 (0.541)	AUROC 0.500 (0.510)	AUPR 0.500 (0.394)	Prec@1 93.750 (84.963)
Epoch: [1][200/415]	Loss 11.7076 (9.7276)	F1 0.407 (0.523)	AUROC 0.423 (0.506)	AUPR 0.094 (0.391)	Prec@1 68.750 (85.386)
Epoch: [1][300/415]	Loss 9.6899 (10.1433)	F1 0.543 (0.515)	AUROC 0.551 (0.505)	AUPR 0.354 (0.379)	Prec@1 68.750 (84.115)
Epoch: [1][400/415]	Loss 4.5960 (10.0367)	F1 1.000 (0.523)	AUROC 0.500 (0.505)	AUPR 0.500 (0.383)	Prec@1 100.000 (84.336)
Epoch: [1][414/415]	Loss 2.4411 (9.9760)	F1 1.000 (0.524)	AUROC 0.500 (0.505)	AUPR 0.500 (0.388)	Prec@1 100.000 (84.576)
Test: [86/87]	Time 0.028 (0.144)	Loss 0.1202 (0.3368)	F1 1.000 (0.571)	AUROC 0.500 (0.500)	AUPR 0.500 (0.553)	Prec@1 100.000 (89.478)
 * Prec@1 89.478
 * F1 0.571
 * AUROC 0.500
 * AUPR 0.553
Epoch: [2][0/415]	Loss 7.3526 (7.3526)	F1 0.484 (0.484)	AUROC 0.500 (0.500)	AUPR 0.531 (0.531)	Prec@1 93.750 (93.750)
Epoch: [2][100/415]	Loss 7.0531 (10.2196)	F1 0.484 (0.505)	AUROC 0.500 (0.486)	AUPR 0.531 (0.359)	Prec@1 93.750 (83.663)
Epoch: [2][200/415]	Loss 5.0967 (9.8490)	F1 0.484 (0.515)	AUROC 0.500 (0.490)	AUPR 0.500 (0.371)	Prec@1 93.750 (85.106)
Epoch: [2][300/415]	Loss 3.3023 (9.6175)	F1 0.484 (0.517)	AUROC 0.500 (0.494)	AUPR 0.500 (0.385)	Prec@1 93.750 (85.673)
Epoch: [2][400/415]	Loss 8.5269 (9.5905)	F1 0.429 (0.517)	AUROC 0.400 (0.493)	AUPR 0.031 (0.386)	Prec@1 75.000 (85.645)
Epoch: [2][414/415]	Loss 3.0537 (9.5484)	F1 1.000 (0.519)	AUROC 0.500 (0.495)	AUPR 0.500 (0.393)	Prec@1 100.000 (85.844)
Test: [86/87]	Time 0.024 (0.145)	Loss 0.1494 (0.3379)	F1 1.000 (0.559)	AUROC 0.500 (0.500)	AUPR 0.500 (0.553)	Prec@1 100.000 (89.478)
 * Prec@1 89.478
 * F1 0.559
 * AUROC 0.500
 * AUPR 0.553
slurmstepd-gpu-02: error: *** STEP 114842.0 ON gpu-02 CANCELLED AT 2023-02-18T12:13:39 ***
